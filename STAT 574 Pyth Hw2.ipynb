{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               var_name  loss_reduction\n",
      "4  surgery_duration_min        0.638316\n",
      "2                   BMI        0.175907\n",
      "1                   age        0.136569\n",
      "3                   ASA        0.026618\n",
      "0                gender        0.022591\n",
      "0.5183727034120735\n",
      "0.6889763779527559\n",
      "0.8110236220472441\n"
     ]
    }
   ],
   "source": [
    "# Problem 1 - random forest regression  - display variable importance and accuracy scores within 10%, 15%, 20%\n",
    "\n",
    "import pandas\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# read in data\n",
    "hospital=pandas.read_csv(r'C:\\Users\\saedw\\OneDrive\\Desktop\\STAT 574 Data Mining\\HW1STAT574S23\\DATA SETS\\hospital_data.csv')\n",
    "coding={'M': 1, 'F': 0}\n",
    "hospital['gender']=hospital['gender'].map(coding)\n",
    "\n",
    "X=hospital.iloc[:,1:6].values\n",
    "y=hospital.iloc[:,6].values\n",
    "\n",
    "#SPLITTING DATA INTO 80% TRAINING AND 20% TESTING SETS\n",
    "X_train, X_test, y_train, y_test=train_test_split(X, y, test_size=0.20, \n",
    "random_state=348644)\n",
    "\n",
    "#FITTING RANDOM FOREST REGRESSION TREE \n",
    "rf_reg=RandomForestRegressor(n_estimators=100, random_state=323445, \n",
    "max_depth=50, max_features=4)\n",
    "rf_reg.fit(X_train, y_train)\n",
    "\n",
    "#DISPLAYING VARIABLE IMPORTANCE\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "\n",
    "var_names=pandas.DataFrame(['gender','age','BMI','ASA','surgery_duration_min'], columns=['var_name'])\n",
    "loss_reduction=pandas.DataFrame(rf_reg.feature_importances_, columns=['loss_reduction'])\n",
    "var_importance=pandas.concat([var_names, loss_reduction], axis=1)\n",
    "var_importance=var_importance.sort_values(\"loss_reduction\", axis=0, ascending=False)\n",
    "print(var_importance)\n",
    "\n",
    "\n",
    "#COMPUTING PREDICTION ACCURACY FOR TESTING DATA\n",
    "y_pred=rf_reg.predict(X_test)\n",
    "\n",
    "ind10=[]\n",
    "ind15=[]\n",
    "ind20=[]     \n",
    "\n",
    "for sub1, sub2 in zip(y_pred, y_test):\n",
    "    ind10.append(1) if abs(sub1-sub2)<0.10*sub2 else ind10.append(0)\n",
    "    ind15.append(1) if abs(sub1-sub2)<0.15*sub2 else ind15.append(0)\n",
    "    ind20.append(1) if abs(sub1-sub2)<0.20*sub2 else ind20.append(0)\n",
    " \n",
    "#accuracy within 10%\n",
    "accuracy10=sum(ind10)/len(ind10)\n",
    "print(accuracy10)\n",
    "\n",
    "#accuracy within 15%\n",
    "accuracy15=sum(ind15)/len(ind15)\n",
    "print(accuracy15)\n",
    "\n",
    "#accuracy within 20%\n",
    "accuracy20=sum(ind20)/len(ind20)\n",
    "print(accuracy20)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        var_names  loss_reduction\n",
      "2  ratio_to_median_purchase_price        0.474494\n",
      "0              distance_from_home        0.189125\n",
      "6                    online_order        0.151155\n",
      "1  distance_from_last_transaction        0.072273\n",
      "5                 used_pin_number        0.070409\n",
      "4                       used_chip        0.038392\n",
      "3                 repeat_retailer        0.004151\n",
      "Accuracy:  0.9975\n"
     ]
    }
   ],
   "source": [
    "# Problem 2 - random forest binary classifier - variable importance and prediction accuracy\n",
    "import pandas\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "card_data=pandas.read_csv(r'C:\\Users\\saedw\\OneDrive\\Desktop\\STAT 574 Data Mining\\HW1STAT574S23\\DATA SETS\\card_transdata.csv')\n",
    "X=card_data.iloc[:,0:7].values\n",
    "y=card_data.iloc[:,7]\n",
    "\n",
    "#SPLITTING DATA INTO 80% TRAINING AND 20% TESTING SETS\n",
    "X_train, X_test, y_train, y_test=train_test_split(X, y, test_size=0.20, \n",
    "random_state=786756)\n",
    "\n",
    "#FITTING RANDOM FOREST BINARY CLASSIFIER\n",
    "rf_class=RandomForestClassifier(n_estimators=150, criterion='entropy', \n",
    "random_state=778554, max_depth=50, max_features=4)\n",
    "rf_class.fit(X_train, y_train)\n",
    "\n",
    "#DISPLAYING VARIABLE IMPORTANCE\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "\n",
    "var_names=pandas.DataFrame(['distance_from_home','distance_from_last_transaction', 'ratio_to_median_purchase_price',\n",
    "'repeat_retailer', 'used_chip','used_pin_number','online_order'], columns=['var_names'])\n",
    "loss_reduction=pandas.DataFrame(rf_class.feature_importances_, columns=['loss_reduction'])\n",
    "var_importance=pandas.concat([var_names, loss_reduction], axis=1) \n",
    "var_importance=var_importance.sort_values(\"loss_reduction\", axis=0, ascending=False)\n",
    "print(var_importance)\n",
    "\n",
    "\n",
    "# print accuracy score \n",
    "from sklearn.metrics import accuracy_score\n",
    "# store predicted values from testing set\n",
    "y_pred=rf_class.predict(X_test)\n",
    "\n",
    "\n",
    "accuracy=accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(\"Accuracy: \", accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       var_names  loss_reduction\n",
      "3       prevconc        0.484487\n",
      "2       position        0.399035\n",
      "0            age        0.062954\n",
      "1  nyearsplaying        0.053523\n",
      "Accuracy:  0.8666666666666667\n"
     ]
    }
   ],
   "source": [
    "# Problem 3\n",
    "    # construct random forest multinomial classifier - display variable importance and accuracy\n",
    "import pandas\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "concussion_data=pandas.read_csv(r'C:\\Users\\saedw\\OneDrive\\Desktop\\STAT 574 Data Mining\\HW1STAT574S23\\DATA SETS\\concussions_data.csv')\n",
    "#for col in concussion_data:\n",
    "#    print(concussion_data[col].unique())\n",
    "\n",
    "code_position={'Offensive Lineman': 1, 'Cornerback': 2, 'Running Back': 3,'Wide Receiver': 4,\n",
    "'Quarterback': 5}\n",
    "code_concussion={'mild': 1, 'moderate': 2, 'severe': 3}\n",
    "\n",
    "concussion_data['position']=concussion_data['position'].map(code_position)\n",
    "concussion_data['concussion']=concussion_data['concussion'].map(code_concussion)\n",
    "\n",
    "\n",
    "X=concussion_data.iloc[:,0:4]\n",
    "y=concussion_data.iloc[:,4]\n",
    "\n",
    "#SPLITTING DATA INTO 80% TRAINING AND 20% TESTING SETS\n",
    "X_train, X_test, y_train, y_test=train_test_split(X, y, test_size=0.20, random_state=599555)\n",
    "\n",
    "#FITTING RANDOM FOREST FOR MULTINOMIAL CLASSIFIER \n",
    "rf_class=RandomForestClassifier(n_estimators=150, random_state=663474, max_depth=50, max_features=4)\n",
    "rf_class.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "#DISPLAYING VARIABLE IMPORTANCE\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "\n",
    "var_names=pandas.DataFrame(['age','nyearsplaying','position','prevconc'], columns=['var_names'])\n",
    "loss_reduction=pandas.DataFrame(rf_class.feature_importances_, columns=['loss_reduction'])\n",
    "var_importance=pandas.concat([var_names, loss_reduction], axis=1) \n",
    "var_importance=var_importance.sort_values(\"loss_reduction\", axis=0, ascending=False)\n",
    "print(var_importance)\n",
    "\n",
    "# print accuracy score \n",
    "from sklearn.metrics import accuracy_score\n",
    "# store predicted values from testing set\n",
    "y_pred=rf_class.predict(X_test)\n",
    "\n",
    "accuracy=accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(\"Accuracy: \", accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               var_name  loss_reduction\n",
      "4  surgery_duration_min        0.717264\n",
      "2                   BMI        0.130330\n",
      "1                   age        0.113203\n",
      "0                gender        0.020439\n",
      "3                   ASA        0.018765\n",
      "0.541994750656168\n",
      "0.7073490813648294\n",
      "0.8110236220472441\n"
     ]
    }
   ],
   "source": [
    "# Problem 4\n",
    "    # fit gradient boosted regression - display variable importance and accuracy scores 10,15, 20%\n",
    "\n",
    "import pandas\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# read in data\n",
    "hospital=pandas.read_csv(r'C:\\Users\\saedw\\OneDrive\\Desktop\\STAT 574 Data Mining\\HW1STAT574S23\\DATA SETS\\hospital_data.csv')\n",
    "coding={'M': 1, 'F': 0}\n",
    "hospital['gender']=hospital['gender'].map(coding)\n",
    "\n",
    "X=hospital.iloc[:,1:6].values\n",
    "y=hospital.iloc[:,6].values\n",
    "\n",
    "#SPLITTING DATA INTO 80% TRAINING AND 20% TESTING SETS\n",
    "X_train, X_test, y_train, y_test=train_test_split(X, y, test_size=0.20, \n",
    "random_state=348644)\n",
    "\n",
    "#FITTING GRADIENT BOOSTED REGRESSION TREE\n",
    "gbreg_params = {'n_estimators': 1000, 'max_depth': 6, 'learning_rate': 0.01, \n",
    "'loss': 'squared_error'}\n",
    "gb_reg=GradientBoostingRegressor(**gbreg_params)\n",
    "gb_reg.fit(X_train, y_train)\n",
    "\n",
    "#DISPLAYING VARIABLE IMPORTANCE\n",
    "\n",
    "var_names=pandas.DataFrame(['gender','age','BMI','ASA','surgery_duration_min'], columns=['var_name'])\n",
    "loss_reduction=pandas.DataFrame(gb_reg.feature_importances_, columns=['loss_reduction'])\n",
    "var_importance=pandas.concat([var_names, loss_reduction], axis=1)\n",
    "var_importance=var_importance.sort_values(\"loss_reduction\", axis=0, ascending=False)\n",
    "print(var_importance)\n",
    "\n",
    "\n",
    "#COMPUTING PREDICTION ACCURACY FOR TESTING DATA\n",
    "y_pred=gb_reg.predict(X_test)\n",
    "\n",
    "ind10=[]\n",
    "ind15=[]\n",
    "ind20=[]     \n",
    "\n",
    "for sub1, sub2 in zip(y_pred, y_test):\n",
    "    ind10.append(1) if abs(sub1-sub2)<0.10*sub2 else ind10.append(0)\n",
    "    ind15.append(1) if abs(sub1-sub2)<0.15*sub2 else ind15.append(0)\n",
    "    ind20.append(1) if abs(sub1-sub2)<0.20*sub2 else ind20.append(0)\n",
    " \n",
    "#accuracy within 10%\n",
    "accuracy10=sum(ind10)/len(ind10)\n",
    "print(accuracy10)\n",
    "\n",
    "#accuracy within 15%\n",
    "accuracy15=sum(ind15)/len(ind15)\n",
    "print(accuracy15)\n",
    "\n",
    "#accuracy within 20%\n",
    "accuracy20=sum(ind20)/len(ind20)\n",
    "print(accuracy20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        var_names  loss_reduction\n",
      "2  ratio_to_median_purchase_price        0.434809\n",
      "6                    online_order        0.248841\n",
      "0              distance_from_home        0.122693\n",
      "5                 used_pin_number        0.107861\n",
      "4                       used_chip        0.062697\n",
      "1  distance_from_last_transaction        0.023098\n",
      "3                 repeat_retailer        0.000000\n",
      "Accuracy:  0.9975\n"
     ]
    }
   ],
   "source": [
    "# Problem 5\n",
    "    # gradient boosted binary classifier - variable importance and prediction accuracy\n",
    "\n",
    "import pandas\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "card_data=pandas.read_csv(r'C:\\Users\\saedw\\OneDrive\\Desktop\\STAT 574 Data Mining\\HW1STAT574S23\\DATA SETS\\card_transdata.csv')\n",
    "X=card_data.iloc[:,0:7].values\n",
    "y=card_data.iloc[:,7]\n",
    "\n",
    "#SPLITTING DATA INTO 80% TRAINING AND 20% TESTING SETS\n",
    "X_train, X_test, y_train, y_test=train_test_split(X, y, test_size=0.20, \n",
    "random_state=786756)\n",
    "\n",
    "#FITTING GRADIENT BOOSTED BINARY CLASSIFIER\n",
    "gbclass_params = {'n_estimators': 1000, 'max_depth': 6, 'learning_rate': 0.1}\n",
    "gb_class=GradientBoostingClassifier(**gbclass_params)\n",
    "gb_class.fit(X_train, y_train)\n",
    "\n",
    "#DISPLAYING VARIABLE IMPORTANCE\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "\n",
    "var_names=pandas.DataFrame(['distance_from_home','distance_from_last_transaction', 'ratio_to_median_purchase_price',\n",
    "'repeat_retailer', 'used_chip','used_pin_number','online_order'], columns=['var_names'])\n",
    "loss_reduction=pandas.DataFrame(gb_class.feature_importances_, columns=['loss_reduction'])\n",
    "var_importance=pandas.concat([var_names, loss_reduction], axis=1) \n",
    "var_importance=var_importance.sort_values(\"loss_reduction\", axis=0, ascending=False)\n",
    "print(var_importance)\n",
    "\n",
    "# print accuracy score \n",
    "from sklearn.metrics import accuracy_score\n",
    "# store predicted values from testing set\n",
    "y_pred=gb_class.predict(X_test)\n",
    "\n",
    "\n",
    "accuracy=accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(\"Accuracy: \", accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       var_names  loss_reduction\n",
      "3       prevconc        0.532275\n",
      "2       position        0.386110\n",
      "0            age        0.046393\n",
      "1  nyearsplaying        0.035222\n",
      "Accuracy:  0.8380952380952381\n"
     ]
    }
   ],
   "source": [
    "# Problem 6\n",
    "    # gradient boosted multinomial classifier - variable importance and accuracy\n",
    "\n",
    "import pandas\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "concussion_data=pandas.read_csv(r'C:\\Users\\saedw\\OneDrive\\Desktop\\STAT 574 Data Mining\\HW1STAT574S23\\DATA SETS\\concussions_data.csv')\n",
    "#for col in concussion_data:\n",
    "#    print(concussion_data[col].unique())\n",
    "\n",
    "code_position={'Offensive Lineman': 1, 'Cornerback': 2, 'Running Back': 3,'Wide Receiver': 4,\n",
    "'Quarterback': 5}\n",
    "code_concussion={'mild': 1, 'moderate': 2, 'severe': 3}\n",
    "\n",
    "concussion_data['position']=concussion_data['position'].map(code_position)\n",
    "concussion_data['concussion']=concussion_data['concussion'].map(code_concussion)\n",
    "\n",
    "X=concussion_data.iloc[:,0:4]\n",
    "y=concussion_data.iloc[:,4]\n",
    "\n",
    "#SPLITTING DATA INTO 80% TRAINING AND 20% TESTING SETS\n",
    "X_train, X_test, y_train, y_test=train_test_split(X, y, test_size=0.20, \n",
    "random_state=566033)\n",
    "\n",
    "#FITTING GRADIENT BOOSTED MULTINOMIAL CLASSIFIER\n",
    "gbmclass_params = {'n_estimators': 1000, 'max_depth': 6, 'learning_rate': 0.1}\n",
    "gb_mclass=GradientBoostingClassifier(**gbmclass_params)\n",
    "gb_mclass.fit(X_train, y_train)\n",
    "\n",
    "#DISPLAYING VARIABLE IMPORTANCE\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "\n",
    "var_names=pandas.DataFrame(['age','nyearsplaying','position','prevconc'], columns=['var_names'])\n",
    "loss_reduction=pandas.DataFrame(gb_mclass.feature_importances_, columns=['loss_reduction'])\n",
    "var_importance=pandas.concat([var_names, loss_reduction], axis=1) \n",
    "var_importance=var_importance.sort_values(\"loss_reduction\", axis=0, ascending=False)\n",
    "print(var_importance)\n",
    "\n",
    "# print accuracy score \n",
    "from sklearn.metrics import accuracy_score\n",
    "# store predicted values from testing set\n",
    "y_pred=gb_mclass.predict(X_test)\n",
    "\n",
    "accuracy=accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(\"Accuracy: \", accuracy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1969ab0a0901f5666ce79356cb491fce788d811519b13a983a274391eee20d8b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
